{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.31.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import os\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import math\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import clear_output\n",
    "from sklearn import model_selection,linear_model,metrics\n",
    "\n",
    "# Model Evaluation Metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score,recall_score,f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Model Selection\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV ,StratifiedKFold\n",
    "from sklearn.linear_model  import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import neighbors\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (AdaBoostClassifier , GradientBoostingClassifier, AdaBoostClassifier ,\n",
    "                             RandomForestClassifier,RandomForestRegressor, BaggingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "\n",
    "class StackingModel:\n",
    "    \"\"\"\n",
    "    A class for stacking models which facilitates ensemble learning by using predictions of \n",
    "    several base models as input for a meta-model to improve prediction accuracy.\n",
    "\n",
    "    Attributes:\n",
    "        base_models (list): A list of tuples, each containing a model and its parameters.\n",
    "        meta_model (object): The meta-estimator model that will be trained on the out-of-fold predictions of the base models.\n",
    "        oof_train (numpy.ndarray): Array storing out-of-fold predictions for the training data.\n",
    "        oof_test (numpy.ndarray): Array storing averaged predictions for the test data from all base models.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.base_models = []\n",
    "        self.meta_model = None\n",
    "        self.oof_train = None\n",
    "        self.oof_test = None\n",
    "        self.metric = accuracy_score\n",
    "\n",
    "    def add_base_models(self, models):\n",
    "        \"\"\" \n",
    "        Add multiple base models to the ensemble.\n",
    "        \n",
    "        Parameters:\n",
    "            models (list): A list of tuples where each tuple contains a model class and its corresponding parameters.\n",
    "        \"\"\"\n",
    "        self.base_models.extend(models)\n",
    "        \n",
    "    def get_base_models(self):\n",
    "        \"\"\" Return the list of base models added to the ensemble. \"\"\"\n",
    "        return self.base_models\n",
    "\n",
    "    def set_meta_model(self, model):\n",
    "        \"\"\" Set the meta-model that will use the base models' out-of-fold predictions as features.\n",
    "        \n",
    "        Parameters:\n",
    "            model (object): An instance of the model to be used as the meta-model.\n",
    "        \"\"\"\n",
    "        self.meta_model = model\n",
    "        \n",
    "    def get_oof(self, model, params, x_train, y_train, x_test, n_splits=5):\n",
    "        \"\"\"\n",
    "        Generate out-of-fold predictions for the given model and parameters using K-Fold cross-validation.\n",
    "        \n",
    "        Parameters:\n",
    "            model (class): The machine learning model class to be used.\n",
    "            params (dict): Dictionary of parameters to be used for model instantiation.\n",
    "            x_train (DataFrame): Training feature dataset.\n",
    "            y_train (Series): Training target dataset.\n",
    "            x_test (DataFrame): Test feature dataset.\n",
    "            n_splits (int): Number of splits for the K-Fold cross-validation.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: A tuple containing reshaped arrays of out-of-fold predictions for the training data and averaged predictions for the test data.\n",
    "        \"\"\"\n",
    "        ntrain = x_train.shape[0]\n",
    "        ntest = x_test.shape[0]\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "        oof_train = np.zeros((ntrain,))\n",
    "        oof_test_skf = np.empty((n_splits, ntest))\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
    "            x_tr = x_train.iloc[train_index]\n",
    "            y_tr = y_train.iloc[train_index]\n",
    "            x_te = x_train.iloc[test_index]\n",
    "\n",
    "            clone_model = model(**params)\n",
    "            clone_model.fit(x_tr, y_tr)\n",
    "\n",
    "            oof_train[test_index] = clone_model.predict(x_te)\n",
    "            oof_test_skf[i, :] = clone_model.predict(x_test)\n",
    "\n",
    "        oof_test = oof_test_skf.mean(axis=0)\n",
    "        return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "    \n",
    "    def get_oof_list(self, x_train, y_train, x_test):\n",
    "        ntrain = x_train.shape[0]\n",
    "        ntest = x_test.shape[0]\n",
    "        num_models = len(self.base_models)\n",
    "        self.oof_train = np.zeros((ntrain, num_models))\n",
    "        self.oof_test = np.zeros((ntest, num_models))\n",
    "    \n",
    "        try:\n",
    "            for idx, (model, params) in enumerate(self.base_models):\n",
    "                oof_train, oof_test = self.get_oof(model, params, x_train, y_train, x_test, n_splits=5)\n",
    "                self.oof_train[:, idx] = oof_train.ravel()\n",
    "                self.oof_test[:, idx] = oof_test.ravel()\n",
    "            return True  # Indicate successful completion\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return False  # Indicate that an error occurred\n",
    "\n",
    "    def meta_fit(self,meta_x_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit the meta-model using the prepared meta training dataset and the provided target values.\n",
    "        \n",
    "        Parameters:\n",
    "            y_train (Series): The target values corresponding to the training dataset.\n",
    "        \"\"\"\n",
    "        self.meta_model.fit(meta_x_train, y_train)  # Make sure y_train is accessible\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict using the meta-model on the provided dataset.\n",
    "        \n",
    "        Parameters:\n",
    "            X (DataFrame): The dataset to make predictions on.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: The predicted values.\"\"\"\n",
    "        \n",
    "        return self.meta_model.predict(X)\n",
    "\n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"\n",
    "        Retrieve and aggregate feature importance from base models, if available.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame: A DataFrame containing the feature importances from each base model.\n",
    "        \"\"\"\n",
    "        feature_importance = pd.DataFrame()\n",
    "        for i, (model, _) in enumerate(self.base_models):\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                feature_importance[f'Model_{i}'] = model.feature_importances_\n",
    "        return feature_importance\n",
    "    \n",
    "    def metric_evaluation(self,metric,y_pred,y_test):\n",
    "        \"\"\"\n",
    "        Evaluate the model using the specified metric.\n",
    "        \n",
    "        Parameters:\n",
    "            metric (function): A function that evaluates the prediction error.\n",
    "            y_pred (numpy.ndarray): Predicted values.\n",
    "            y_test (Series): Actual target values.\n",
    "        \n",
    "        Returns:\n",
    "            float: The calculated metric score.\n",
    "        \"\"\"\n",
    "        return metric(y_test, y_pred)\n",
    "\n",
    "    def plot_feature_importances(self):\n",
    "        \"\"\"\n",
    "        Plot the feature importances of the base models.\n",
    "        \"\"\"\n",
    "        \n",
    "    def plot_feature_importance_corr(self):\n",
    "        \"\"\"\n",
    "        Plot correlations of feature importances between base models.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/preprocessed/adult_census_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'age', 'fnlwgt', 'education', 'education-num',\n",
       "       'capital-gain', 'capital-loss', 'hours-per-week',\n",
       "       'workclass_govermental', 'marital-status_Never-married',\n",
       "       'marital-status_Single', 'occupation_Armed-Forces',\n",
       "       'occupation_Craft-repair', 'occupation_Exec-managerial',\n",
       "       'occupation_Farming-fishing', 'occupation_Handlers-cleaners',\n",
       "       'occupation_Machine-op-inspct', 'occupation_Other-service',\n",
       "       'occupation_Priv-house-serv', 'occupation_Prof-specialty',\n",
       "       'occupation_Protective-serv', 'occupation_Sales',\n",
       "       'occupation_Tech-support', 'occupation_Transport-moving',\n",
       "       'relationship_Separated', 'relationship_Single', 'race_Other',\n",
       "       'race_White', 'sex_Male', 'native-country_Europe',\n",
       "       'native-country_Others', 'native-country_US', 'income_>50K'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('income_>50K', axis=1)\n",
    "y = data['income_>50K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RandomMachines import RandomMachinesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmachines = RandomMachinesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking = StackingModel()\n",
    "\n",
    "stacking.add_base_models([(RandomForestClassifier,rf_params),(ExtraTreesClassifier,et_params),(AdaBoostClassifier,ada_params),(GradientBoostingClassifier,gb_params)])\n",
    "stacking.set_meta_model(xgb.XGBClassifier(learning_rate = 0.02,\n",
    "    n_estimators= 2000,\n",
    "    max_depth= 4,\n",
    "    min_child_weight= 2,\n",
    "    #gamma=1,\n",
    "    gamma=0.9,                        \n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread= -1,\n",
    "    scale_pos_weight=1))\n",
    "stacking.get_base_models()\n",
    "stacking.get_oof_list(X_train,y_train,X_test)\n",
    "stacking.meta_fit(stacking.oof_train,y_train)\n",
    "prediction_test = stacking.predict(stacking.oof_test)\n",
    "print(f'Accuracy is: {sum(y_test==np.asarray(prediction_test))/y_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(sklearn.ensemble._forest.RandomForestClassifier,\n",
       "  {'n_jobs': -1,\n",
       "   'n_estimators': 500,\n",
       "   'warm_start': True,\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'verbose': 0}),\n",
       " (sklearn.ensemble._forest.ExtraTreesClassifier,\n",
       "  {'n_jobs': -1,\n",
       "   'n_estimators': 500,\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'verbose': 0}),\n",
       " (sklearn.ensemble._weight_boosting.AdaBoostClassifier,\n",
       "  {'n_estimators': 500, 'learning_rate': 0.75})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking.get_base_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
